{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9de7053d",
   "metadata": {},
   "source": [
    "## Grandient Boosting Modeling for Reading ##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b946f70d",
   "metadata": {},
   "source": [
    "The models are:\n",
    "- CatBoost\n",
    "- XGBoost\n",
    "- LightGBM\n",
    "- HistGradientBoosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5bb90a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b4b382d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "# import os\n",
    "# os.environ['KMP_DUPLICATE_LIB_OK']='True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db4b428a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score, precision_score, recall_score, f1_score, matthews_corrcoef, roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b13b966c",
   "metadata": {},
   "source": [
    "### Prepare data ###"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22799878",
   "metadata": {},
   "source": [
    "Loading the data cleaned from [EDA.ipynb](../processing/EDA.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "57ba8e00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(955, 90)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('../processing/DATA_Texas_District_v2.csv', sep=',', header=0)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb94a593",
   "metadata": {},
   "source": [
    "**Get dummies for categorical feature `Locale`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1e486664",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(955, 101)\n"
     ]
    }
   ],
   "source": [
    "df = pd.get_dummies(df, columns=['Locale'], prefix='Locale')\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e66bdd3",
   "metadata": {},
   "source": [
    "**Split data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e76202b6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(955, 90)\n"
     ]
    }
   ],
   "source": [
    "labels = ['Label_Math', 'Label_Reading', 'Label_All']\n",
    "cols_drop = ['% Tested Math G3 Diff',\n",
    "            '% Tested Math G4 Diff',\n",
    "            '% Tested Math G5 Diff',\n",
    "            '% Tested Math G6 Diff',\n",
    "            '% Tested Math G7 Diff',\n",
    "            '% Tested Math G8 Diff',\n",
    "            'District #', 'County #']\n",
    "\n",
    "\n",
    "df['Label'] = df['Label_Reading'].apply(lambda x: 0 if x == -1\n",
    "                                             else 1 if x == 0\n",
    "                                             else 2)\n",
    "\n",
    "y = df['Label'].values\n",
    "X = df.drop(columns=labels + cols_drop + ['Label']).copy()\n",
    "columns = df.drop(columns=labels + cols_drop + ['Label']).columns.to_list()\n",
    "categorical_cols = [c for c in columns if 'Locale' in c]\n",
    "categorical_cols_idx = [columns.index(c) for c in columns if 'Locale' in c]\n",
    "numerical_cols = [c for c in columns if c not in categorical_cols]\n",
    "\n",
    "random_state=123\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y,\n",
    "                                                    random_state=random_state, shuffle=True)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d3709a5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Train</th>\n",
       "      <th>Test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>173</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>409</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>182</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Label  Train  Test\n",
       "0      0    173    43\n",
       "1      1    409   102\n",
       "2      2    182    46"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values, counts = np.unique(y_train, return_counts=True)\n",
    "values_test, counts_test = np.unique(y_test, return_counts=True)\n",
    "pd.DataFrame({'Label': values.tolist(), 'Train': counts.tolist(), 'Test': counts_test.tolist()})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebfed6b7",
   "metadata": {},
   "source": [
    "### Experiment with the Feature Sets selected from [Feature_Selection_Reading.ipynb](../processing/Feature_Selection_Reading.ipynb) ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "84301263",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Set 1: n=57 selected by 4 or more selection methods\n",
      "Feature Set 2: n=27 selected by 5 or more selection methods\n",
      "Feature Set 3: n=14 selected by 6 or more selection methods\n",
      "Feature Set 4: n=90 from No reduction\n"
     ]
    }
   ],
   "source": [
    "feature_selected = pd.read_csv('../Processing/Feature_Selection_Reading_Results.csv', sep=',', header=0)\n",
    "feature_selected = feature_selected.groupby('feature', as_index=False).agg({'selected': 'sum'})\n",
    "n_selected_by = [4, 5, 6, 0]\n",
    "\n",
    "for i, n in enumerate(n_selected_by):\n",
    "    n_feat = len(columns) if n == 0 else feature_selected[feature_selected['selected']>=n].shape[0]\n",
    "    n_sel = 'from No reduction' if n ==0 else 'selected by '+str(n)+' or more selection methods'\n",
    "    print('Feature Set {}: n={} {}'.format(i+1, n_feat, n_sel))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f672ba72",
   "metadata": {},
   "source": [
    "**n iteration for models**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6d5cb183",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_n_iter (param_grid):\n",
    "    n_iter_ratio = 0.2\n",
    "    n_iter = 1\n",
    "    for v in param_grid.values(): n_iter*=len(v)\n",
    "    n_iter *= n_iter_ratio\n",
    "\n",
    "    return int(n_iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40be0d19",
   "metadata": {},
   "source": [
    "### Modeling ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8e0d734d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rounds = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bed6e9e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_report(estimator, param_grid, name, fit_params):\n",
    "    result = pd.DataFrame()\n",
    "    avg = 'weighted'\n",
    "    cv=5\n",
    "    \n",
    "    n_iter=get_n_iter(param_grid)\n",
    "    print('{} n_iter: {:0.0f}'.format(name, n_iter))     \n",
    "    if name == 'CatBoost': n_iter=100\n",
    "        \n",
    "    for n in n_selected_by:\n",
    "        if n == 0:\n",
    "            features = columns \n",
    "            method = \"No Reduction\"\n",
    "        else:\n",
    "            features = feature_selected[feature_selected['selected']>=n]['feature'].to_list()\n",
    "            method = str(n)+' or more'\n",
    "         \n",
    "        X_train2 = X_train.loc[:, features].copy()\n",
    "        X_test2 = X_test.loc[:, features].copy()        \n",
    "                \n",
    "        categorical_cols_inx=[features.index(f) for f in features if f in categorical_cols]\n",
    "        if len(categorical_cols_inx) > 0:\n",
    "            if (name == 'LightGBM'): fit_params['categorical_feature']=categorical_cols_inx\n",
    "            if (name == 'CatBoost'): fit_params['cat_features']=categorical_cols_inx\n",
    "            if (name == 'HistGB'): estimator.set_params(**{'categorical_features': categorical_cols_inx})\n",
    "            if (name == 'XGBoost'):\n",
    "                X_train2=X_train2.astype({features[c]: 'category' for c in categorical_cols_inx})\n",
    "                X_test2=X_test2.astype({features[c]: 'category' for c in categorical_cols_inx})\n",
    "        else: \n",
    "            if (name == 'LightGBM'): fit_params['categorical_feature']=None\n",
    "            if (name == 'CatBoost'): fit_params['cat_features']=None\n",
    "            if (name == 'HistGB'): estimator.set_params(**{'categorical_features': None})\n",
    "\n",
    "        grid = RandomizedSearchCV(estimator, param_distributions=param_grid, cv=cv, n_jobs=-1, \n",
    "                              random_state=random_state, n_iter=n_iter)\n",
    "\n",
    "        start_cpu = time.process_time()\n",
    "        start_wall = time.time()\n",
    "        \n",
    "        if name == 'HistGB': \n",
    "            grid.fit(X_train2, y_train)\n",
    "        elif name == 'LightGBM':\n",
    "            fit_params['eval_set'] =  [(X_test2.values, y_test)]\n",
    "            grid.fit(X_train2.values, y_train, **fit_params)\n",
    "        else:\n",
    "            fit_params['eval_set'] =  [(X_test2, y_test)]\n",
    "            grid.fit(X_train2, y_train, **fit_params)            \n",
    "       \n",
    "        if name == 'XGBoost': grid.best_estimator_.save_model(\"categorical-model.json\")\n",
    "            \n",
    "        cpu_time = time.process_time() - start_cpu\n",
    "        wall_time = time.time() - start_wall\n",
    "        y_pred = grid.best_estimator_.predict(X_test2)\n",
    "        \n",
    "        temp = {'Model': name,\n",
    "                'n Selected': len(features),\n",
    "                'Method': method,\n",
    "                'best_params': grid.best_params_,\n",
    "                'Best Accuracy': grid.best_score_, \n",
    "                'Train Accuracy': grid.best_estimator_.score(X_train2, y_train),\n",
    "                'Test Accuracy': accuracy_score(y_test, y_pred),\n",
    "                'Precision': precision_score(y_test, y_pred, average=avg),\n",
    "                'Recall': recall_score(y_test, y_pred, average=avg),\n",
    "                'MCC': matthews_corrcoef(y_test, y_pred), \n",
    "                'F1': f1_score(y_test, y_pred, average=avg),\n",
    "#                 'ROC': roc_auc_score(y_test, grid.best_estimator_.predict_proba(X_test2), multi_class='ovr', average=avg),\n",
    "                'conf_mat': confusion_matrix(y_test, y_pred), \n",
    "                'Prediction': y_pred,\n",
    "                'predict_proba': grid.best_estimator_.predict_proba(X_test2),\n",
    "                'Features': features,\n",
    "                'estimator': grid.best_estimator_,\n",
    "                'classification_report': classification_report(y_test, y_pred),\n",
    "                'Train Time CPU': cpu_time,\n",
    "                'Train Time Wall': wall_time,\n",
    "                'n_iter': n_iter}\n",
    "        result = pd.concat([result, pd.DataFrame([temp])], ignore_index=True)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cde216f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a40b353",
   "metadata": {},
   "source": [
    "**CatBoost**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b710808c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CatBoost n_iter: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/ML310/lib/python3.10/site-packages/catboost/core.py:1411: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  self._init_pool(data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, weight,\n",
      "/opt/anaconda3/envs/ML310/lib/python3.10/site-packages/catboost/core.py:1411: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  self._init_pool(data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, weight,\n",
      "/opt/anaconda3/envs/ML310/lib/python3.10/site-packages/catboost/core.py:1411: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  self._init_pool(data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, weight,\n",
      "/opt/anaconda3/envs/ML310/lib/python3.10/site-packages/catboost/core.py:1411: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  self._init_pool(data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, weight,\n",
      "/opt/anaconda3/envs/ML310/lib/python3.10/site-packages/catboost/core.py:1411: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  self._init_pool(data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, weight,\n",
      "/opt/anaconda3/envs/ML310/lib/python3.10/site-packages/catboost/core.py:1411: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  self._init_pool(data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, weight,\n",
      "/opt/anaconda3/envs/ML310/lib/python3.10/site-packages/catboost/core.py:1411: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  self._init_pool(data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, weight,\n",
      "/opt/anaconda3/envs/ML310/lib/python3.10/site-packages/catboost/core.py:1411: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  self._init_pool(data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, weight,\n",
      "/opt/anaconda3/envs/ML310/lib/python3.10/site-packages/catboost/core.py:1411: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  self._init_pool(data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, weight,\n",
      "/opt/anaconda3/envs/ML310/lib/python3.10/site-packages/catboost/core.py:1411: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  self._init_pool(data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, weight,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.78 s, sys: 547 ms, total: 3.32 s\n",
      "Wall time: 7.98 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "params = {'iterations': [50, 100, 200],\n",
    "'depth': [3, 6, 9],\n",
    "'min_data_in_leaf': [1, 5, 10],\n",
    "'learning_rate': [0.01, 0.1, 0.2, 0.3],\n",
    "'l2_leaf_reg': [0, 0.01, 0.1, 1, 10],\n",
    "'random_strength': [0, 5, 10, 15]}\n",
    "\n",
    "fit_params = {'early_stopping_rounds': rounds}\n",
    "\n",
    "estimator = CatBoostClassifier(random_seed=random_state, verbose=False, \n",
    "                               loss_function='MultiClass', eval_metric=\"MultiClass\", one_hot_max_size=4, border_count=254)\n",
    "                               \n",
    "result_report=model_report(estimator, params, 'CatBoost', fit_params)\n",
    "results=pd.concat([results, result_report], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75ebb1bd",
   "metadata": {},
   "source": [
    "**XGBoost**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "016ef059",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "import xgboost\n",
    "\n",
    "params = {'n_estimators': [50, 100, 200],\n",
    "'max_depth': [1, 6, 0],\n",
    "'min_child_weight': [0, 0.001, 0.1, 1],\n",
    "'learning_rate': [0.01, 0.1, 0.2, 0.3],\n",
    "'alpha': [0,  0.1, 10],\n",
    "'lambda': [0,  0.1, 10],\n",
    "'gamma': [0,  0.1, 10]}\n",
    "\n",
    "estimator = xgboost.XGBClassifier(seed=random_state, objective='multi:softproba', eval_metric='mlogloss', use_label_encoder=False, verbosity=0,\n",
    "                                  num_class=3, tree_method=\"hist\", early_stopping_rounds=rounds, enable_categorical=True, max_cat_to_onehot=4)\n",
    "\n",
    "result_report=model_report(estimator, params, 'XGBoost', {})\n",
    "results=pd.concat([results, result_report], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab2241f0",
   "metadata": {},
   "source": [
    "**LightGBM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1976838c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import lightgbm as lgb\n",
    "\n",
    "params = {'n_estimators': [50, 100, 200],\n",
    "'max_depth': [1, 6, -1],\n",
    "'min_sum_hessian_in_leaf': [0, 0.001, 0.1, 1],\n",
    "'learning_rate': [0.01, 0.1, 0.2, 0.3],\n",
    "'reg_alpha': [0,  0.1, 10],\n",
    "'reg_lambda': [0,  0.1, 10],\n",
    "'min_split_gain': [0,  0.1, 10]}\n",
    "\n",
    "fit_params = {'early_stopping_rounds': rounds}\n",
    "\n",
    "estimator = lgb.LGBMClassifier(random_state=random_state, objective=\"multiclass\", metric=\"multi_logloss\", verbosity=-1, silent=True, force_col_wise=True,\n",
    "                               num_class=3, is_unbalance=True, max_cat_threshold=32)\n",
    "                               \n",
    "result_report=model_report(estimator, params, 'LightGBM', fit_params)\n",
    "results=pd.concat([results, result_report], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e9ad337",
   "metadata": {},
   "source": [
    "**HistGradientBoosting**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbbaa5ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "\n",
    "params = {'max_iter': [50, 100, 200],\n",
    "'max_depth': [1, 6, None],\n",
    "'max_leaf_nodes': [10, 31, 50, 64],\n",
    "'min_samples_leaf': [10, 20, 30],\n",
    "'learning_rate': [0.01, 0.1, 0.2, 0.3],\n",
    "'l2_regularization': [0, 0.01, 0.1, 1, 10]}\n",
    "\n",
    "estimator=HistGradientBoostingClassifier(random_state=random_state, n_iter_no_change=rounds, early_stopping=True)\n",
    "result_report=model_report(estimator, params, 'HistGB', {})\n",
    "results=pd.concat([results, result_report], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fffc639",
   "metadata": {},
   "source": [
    "## Result ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83492a74",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results.sort_values(by=['MCC', 'F1'], ascending=False).head(10)[['Model', 'Method', 'n Selected', 'Test Accuracy', 'MCC', 'F1', 'best_params']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4283317b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results.sort_values(by=['MCC', 'F1'], ascending=False).head(10)['Model'].value_counts().to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c918cf4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results.sort_values(by=['MCC', 'F1'], ascending=False).head(10)['n Selected'].value_counts().sort_index().to_frame()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f599417d",
   "metadata": {},
   "source": [
    "**Accuracy, MCC and F1 Score**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9cd28a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "results2 = pd.DataFrame()\n",
    "for col in ['Train Accuracy', 'Test Accuracy', 'MCC', 'F1']:\n",
    "    temp = results[['Model', 'n Selected'] + [col]].copy()\n",
    "    temp['Score'] = col\n",
    "    temp.rename(columns={col: 'Score value'}, inplace=True)\n",
    "    results2 = pd.concat([results2, temp], ignore_index=True)\n",
    "results2=results2.astype({'n Selected': 'int32'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "977a401b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(rc={'figure.figsize':(20,20)})\n",
    "sns.set_theme(style='whitegrid')\n",
    "sns.set(font_scale=1.8)\n",
    "\n",
    "g = sns.catplot(x=\"n Selected\", y=\"Score value\", hue=\"Score\", col=\"Model\",\n",
    "                capsize=.2, palette=\"magma\", height=6, aspect=.75,\n",
    "                kind=\"point\", data=results2)\n",
    "g.despine(left=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6aea2d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = results['Model'].unique().tolist()\n",
    "temp=results.sort_values(by=['Model', 'MCC', 'F1'], ascending=False)\n",
    "\n",
    "best_per_model_idx = []\n",
    "for i in range(len(temp.index)):\n",
    "    if i % (n+1) == 0: best_per_model_idx.append(temp.index[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b525c169",
   "metadata": {},
   "source": [
    "**Confusion Matrix**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d40e0a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.plotting import plot_confusion_matrix\n",
    "import matplotlib.ticker as mticker\n",
    "\n",
    "def ticks(x, position):\n",
    "    if position == 1: return 'Loss'\n",
    "    if position == 2: return 'Exp'\n",
    "    if position == 3: return 'Gain'\n",
    "    \n",
    "fig, axes=plt.subplots(1,len(best_per_model_idx), figsize=(20,10))\n",
    "sns.set(font_scale=1.2)\n",
    "\n",
    "for idx, i in zip(sorted(best_per_model_idx), range(len(best_per_model_idx))):\n",
    "    plot_confusion_matrix(axis=axes[i], conf_mat=results.loc[idx, 'conf_mat'],\n",
    "                          show_absolute=True, show_normed=True)\n",
    "    title='{} (n={:0.0f})'.format(results.loc[idx, 'Model'], results.loc[idx, 'n Selected'])\n",
    "    axes[i].set_title(title, fontsize=20)\n",
    "    if (i > 0): axes[i].set(xlabel='', ylabel='')\n",
    "    else : axes[i].set(xlabel='Predicted Label', ylabel='True Label')\n",
    "    axes[i].xaxis.set_major_formatter(mticker.FuncFormatter(ticks))\n",
    "    axes[i].yaxis.set_major_formatter(mticker.FuncFormatter(ticks))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0a49870",
   "metadata": {},
   "source": [
    "**ROC Curve**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a1a5aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "classes=[0, 1, 2]\n",
    "y_test_bin=label_binarize(y_test, classes=classes)\n",
    "\n",
    "fig, axes=plt.subplots(1,len(best_per_model_idx), figsize=(20,5))\n",
    "sns.set(font_scale=1)\n",
    "\n",
    "for idx, i in zip(sorted(best_per_model_idx), range(len(best_per_model_idx))):\n",
    "    fpr, tpr = {}, {}\n",
    "\n",
    "    for c in classes:\n",
    "        fpr[c], tpr[c], _ = roc_curve(y_test_bin[:, c], results.loc[idx, 'predict_proba'][:, c])\n",
    "        axes[i].plot(fpr[c], tpr[c], lw=2, label='{} (AUC={:0.2f})'.format(ticks(c,c+1), auc(fpr[c], tpr[c])))\n",
    "    \n",
    "    title='{} (n={:0.0f})'.format(results.loc[idx, 'Model'], results.loc[idx, 'n Selected'])\n",
    "    axes[i].set_title(title, fontsize=20)\n",
    "    axes[i].set_xlabel(\"False Postive Rate\")\n",
    "    axes[0].set_ylabel(\"True Positive Rate\")\n",
    "    axes[i].legend(loc=\"best\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1afde14e",
   "metadata": {},
   "source": [
    "**Precision-Recall Curve**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba07e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "classes=[0, 1, 2]\n",
    "y_test_bin=label_binarize(y_test, classes=classes)\n",
    "\n",
    "fig, axes=plt.subplots(1,len(best_per_model_idx), figsize=(20,5))\n",
    "sns.set(font_scale=1)\n",
    "\n",
    "for idx, i in zip(sorted(best_per_model_idx), range(len(best_per_model_idx))):\n",
    "    prec, rec = {}, {}\n",
    "\n",
    "    for c in classes:\n",
    "        prec[c], rec[c], _ = precision_recall_curve(y_test_bin[:, c], results.loc[idx, 'predict_proba'][:, c])\n",
    "        axes[i].plot(rec[c], prec[c], lw=2, label='{}'.format(ticks(c,c+1)))\n",
    "    \n",
    "    title='{} (n={:0.0f})'.format(results.loc[idx, 'Model'], results.loc[idx, 'n Selected'])\n",
    "    axes[i].set_title(title, fontsize=20)\n",
    "    axes[i].set_xlabel(\"Recall\")\n",
    "    axes[0].set_ylabel(\"Precision\")\n",
    "    axes[i].legend(loc=\"best\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce46552e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, i in zip(sorted(best_per_model_idx), range(len(best_per_model_idx))):\n",
    "    title='{} (n={:0.0f})'.format(results.loc[idx, 'Model'], results.loc[idx, 'n Selected'])\n",
    "    print(title, '\\n', results.loc[idx, 'classification_report'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83930f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.sort_values(by=['MCC'], ascending=False).to_csv('Modeling_GB_Reading.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "b530cbb57870e8c17e0b147b89ef717ce29e19d06452b992ddf605f8bc0a986d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
